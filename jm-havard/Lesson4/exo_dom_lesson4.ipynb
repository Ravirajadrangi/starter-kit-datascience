{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def region_car_url(region):\n",
    "\n",
    "    url = \"https://www.leboncoin.fr/voitures/offres/\" + \\ region + \"/?th=1&parrot=0&brd=Renault&mdl=Zoe\"\n",
    "    text_lb = requests.get(url)\n",
    "    soup = BeautifulSoup(text_lb.text,  'html.parser')\n",
    "\n",
    "# On identifie la dernieère page\n",
    "\n",
    "    der_page = list(map(lambda x: x['href'], soup.find_all(class_='element page static')))\n",
    "\n",
    "    if len(der_page) != 0:\n",
    "        idx_der_page = der_page[0].index(\"=\")\n",
    "        nb_der_page = int(der_page[0][idx_der_page + 1])\n",
    "    else:\n",
    "    nb_der_page = 1\n",
    "\n",
    "    list_url_zoe = list()\n",
    "    for i in range(1, nb_der_page + 1):\n",
    "            url_i = \"https://www.leboncoin.fr/voitures/offres/\" + \\ region + \"/?th=1&parrot=\" + str(i) + \"&brd=Renault&mdl=Zoe\"\n",
    "    text_lb_i = requests.get(url_i)\n",
    "    soup = BeautifulSoup(text_lb_i.text,  'html.parser')\n",
    "    ml_url = map(lambda x: x['href'], soup.find_all(class_='list_item clearfix trackable'))\n",
    "    list_url_zoe.extend(ml_url)\n",
    "    \n",
    "    return list_url_zoe\n",
    "\n",
    "\n",
    "def extraction_information(url):\n",
    "\n",
    "    text_page = requests.get(\"https:\" + url)\n",
    "    soup_page = BeautifulSoup(text_page.text, 'html.parser')\n",
    "    title = soup_page.find(class_=\"no-border\").text.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    clear_title = [i.lower() for i in title.split(\" \") if i != \" \"]\n",
    "    \n",
    "    \n",
    "    liste_name_modele = ['life', 'intens', 'zen']\n",
    "    modele = [i for i in clear_title if i in liste_name_modele]\n",
    "\n",
    "    type_car = \"\"\n",
    "    # définition du type de voiture\n",
    "    for idx, i in enumerate(clear_title):\n",
    "        if i == 'charge':\n",
    "            if clear_title[idx + 2] == \"type\":\n",
    "                type_car = clear_title[idx] + \" \" + clear_title[idx + 1] + \" \" + clear_title[idx + 2] \\ + \" \" + clear_title[idx + 3]\n",
    "            else:\n",
    "                type_car = clear_title[idx] + \" \" + clear_title[idx + 1]\n",
    "            break\n",
    "\n",
    "        elif i == 'type':\n",
    "            type_car = clear_title[idx] + \" \" + clear_title[idx + 1]\n",
    "            break\n",
    "        modele = ''.join(modele)\n",
    "   \n",
    "    price = soup_page.find_all(class_='value')[0].text.replace(\"\\xa0\", \"\").replace(\"\\n\", \"\").replace(\" \", \"\").replace(\"€\",\"\")\n",
    "    year = soup_page.find_all(class_='value')[4].text.replace(\"\\xa0\", \"\").replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "    distance = soup_page.find_all(class_='value')[5].text.replace(\"\\xa0\", \"\").replace(\"\\n\", \"\").replace(\" \", \"\").replace(\"KM\",\"\")\n",
    "\n",
    "    # Le vendeur est il un professionnel\n",
    "    \n",
    "    pro = soup_page.find_all(class_='ispro')\n",
    "    if len(pro) == 0:\n",
    "        ispro = 'Particulier'\n",
    "    else:\n",
    "        ispro = soup_page.find_all(class_='ispro')[0].text.split(\" \")[0]\n",
    "\n",
    "  \n",
    "    idx_description = len(soup_page.find_all(class_='value'))\n",
    "    description = soup_page.find_all(class_='value')[idx_description - 1].text\n",
    "    pattern_regex = (\"(0|\\\\+33|0033)[1-9]([\\S  \\s -,.][0-9]{1,2}){4}\")\n",
    "    find_patern = re.compile(pattern_regex).search(description.strip())\n",
    "\n",
    "    if find_patern is None:\n",
    "        mobile_number = 'None'\n",
    "    else:\n",
    "        mobile_number = find_patern.group()\n",
    "\n",
    "    value_return = {'Modele': modele, 'type': type_car, 'Année': year, 'Km': distance, 'Vendeur': ispro,'Prix €': price, 'Numéro': mobile_number}\n",
    "\n",
    "    return value_return\n",
    "\n",
    "\n",
    "\n",
    "def transform_data(ma_table) :\n",
    "    for i in range(ma_table.shape[0]) :\n",
    "\n",
    "        if ma_table.loc[i,\"type\"]!=\"\" :\n",
    "\n",
    "            type_c = ma_table.loc[i,\"type\"].split(\" \")\n",
    "            type_url = \"+\".join(type_c)\n",
    "            url = \"http://www.lacentrale.fr/cote-auto-renault-zoe-\"+ ma_table.loc[i,\"Modele\"] + \"+\" \\ +type_url+\"-\"+ ma_table.loc[i,\"Année\"] +\".html\"\n",
    "        else :\n",
    "            url = \"http://www.lacentrale.fr/cote-auto-renault-zoe-\"+ ma_table.loc[i,\"Modele\"]  \\ +\"-\"+ ma_table.loc[i,\"Année\"] +\".html\"\n",
    "\n",
    "        text_lc = requests.get(url)\n",
    "        soup_lc = BeautifulSoup(text_lc.text,  'html.parser')\n",
    "\n",
    " \n",
    "        price_init = soup_lc.find(class_=\"f24 bGrey9L txtRed pL15 mL15\")\n",
    "\n",
    "        if price_init is not None:\n",
    "            price_lc = soup_lc.find(class_=\"f24 bGrey9L txtRed pL15 mL15\").text.replace(\"\\n\",\"\") \\ .replace(\" \",\"\").replace(\"€\",\"\")\n",
    "        else : \n",
    "            price_lc = np.nan\n",
    "        ma_table.loc[i,\"Price Central €\"] = price_lc\n",
    "\n",
    "    return ma_table \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fullfil():\n",
    "    # crée la table de remplissage\n",
    "    columns_name = ['Modele', 'type', 'Année', 'Km', 'Vendeur', 'Prix €', 'Numéro']\n",
    "    data_zoe = pd.DataFrame(colml_urlumns=columns_name)\n",
    "\n",
    "    # On remplit pour chaque region\n",
    "    for region in ['ile_de_france', 'aquitaine', 'provence_alpes_cote_d_azur']:\n",
    "\n",
    "        liste_car = region_car_url(region)\n",
    "\n",
    "        for v in liste_car:\n",
    "            it_dict = extraction_information(v)\n",
    "            data_zoe = data_zoe.append(it_dict, ignore_index=True)\n",
    "\n",
    "    jmh_zoe = transform_data(data_zoe)\n",
    "\n",
    "    jmh_zoe[\"Prix €\"] = jmh_zoe[\"Prix €\"].apply(float)\n",
    "    jmh_zoe[\"Km\"] = jmh_zoe[\"Km\"].apply(float)\n",
    "    jmh_zoe[\"Price Central €\"] = jmh_zoe[\"Price Central €\"].apply(float)\n",
    "\n",
    "    jmh_zoe[\"Value Argus\"] = jmh_zoe[\"Prix €\"] - jmh_zoe[\"Price Central €\"]\n",
    "\n",
    "    jmh_zoe[\"Numéro\"] = jmh_zoe[\"Numéro\"].apply(lambda x : x.replace(\".\",\"\").replace(\"/\",\"\").replace(\" \",\"\"))\n",
    "    jmh_zoe[\"Numéro\"] = jmh_zoe[\"Numéro\"].apply(lambda x : None if len(x)!=10  else x) \n",
    "\n",
    "\n",
    "    return jmh_zoe\n",
    "\n",
    "# execution du code\n",
    "\n",
    "ma_table = fullfil()\n",
    "path = \"/Users/havard-macpro/Documents/Telecom_paristech/cours/INFMDI721 - kit big data/exercices\"\n",
    "ma_table.to_csv(path + \"export_le_boncoin.csv\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
