{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGING DATAFRAME : methode join, la taille du DF final dépend du \"how= inner, outer, left inner...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX : 2 csv assez lourds : comment merger les 2 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pdb\n",
    "\n",
    "insee\n",
    "insee2\n",
    "\n",
    "insee1.columns\n",
    "insee1[\"code insee\"]\n",
    "insee2[\"code geo\"]\n",
    "\n",
    "# Pas la même taille de DF\n",
    "\n",
    "pd.merge(insee1,insee2, left_on = 'code insee', right_on = 'code geo').shape\n",
    "# LE MERGE EST FORTEMENT LIE A LA QUESTION DE NORMALISATION DES VALEURS DES COLONNES DES 2 DF ! Car sinon, il ne va pas merger cetaines lignes\n",
    "\n",
    "insee1['code insee'].ix[36697]\n",
    "# Pas le même type : sur un DF ce sont des strings, sur l'autre des int : 1001 à 01001\n",
    "\n",
    "def strip_corse(val)\n",
    "    if type(val)==int:\n",
    "        return val\n",
    "    else:\n",
    "        return int(val)\n",
    "    \n",
    "insee2[\" \"].apply(strip_corse)\n",
    "\n",
    "# VOIR APPLY : apply sur une colonne : passe en parametre chaque el de la colonne et applique la fonction dessus.\n",
    "insee2[\" \"] = insee2[\" \"].apply(strip_corse)\n",
    "# Apres avoir appliquer strip_corse, on obtient bcp plus de lignes dans le resultat de notre MERGE ==> Attention à la normalisation quand MERGE !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIVOT comment passer du format wide to long et long to wide : IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "releves = [['lundi', 'temperature','28']...]\n",
    "# Idée : comment passer d'un format long à un format wide\n",
    "\n",
    "cities_data = DataFrame(relevés, columns=['day', 'observations', 'value'])\n",
    "# pivoter l'info pour avoir ce qui nous intéresse en pivot\n",
    "cities_data.pivot('day','observation,'value')\n",
    "\n",
    "pd.melt(cities_data_wide, id_var=['day'], value_var='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MELT (inverse de pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_index\n",
    "# d'un côté on definit les observation, appeler mon melt avec en value les observations \n",
    "# Le melt ==> FILTRAGE HYPER SIMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GROUP BY : Comment à partir d'un attribut passer à un tableau dynamique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lire le fichier caméra\n",
    "cameras = pd.read_csv('cameras.csv', sep=';')\n",
    "# La 1ere ligne contient le type => corrompre le DF \n",
    "cameras.head()\n",
    "# supprimer la permiere ligne\n",
    "cameras = cameras.ix[1,:] # supprimer la 1ere ligne via un bete slicer\n",
    "# Tout est des chiffres sauf la col modele -> convertir tout sauf cette col en float --> cameras.set_index[\"modele\"] : permet de mettre la colonne qui nous embête en index. \n",
    "# On met en index la colonne qu'on veut isoler pour travailler sur le reste du DF : ex, ici, on veut convertir le reste du DF en float sauf la col modele qui est en string.\n",
    "\n",
    "# Utiliser des regex sur les DF\n",
    "\n",
    "cameras['modele'] # faire une regex pour extraire la marque et le numéro du modèle\n",
    "cameras['Model'].str.extract('(\\w)(\\.*)')\n",
    "str.lower()\n",
    "str.split()\n",
    "\n",
    "# RENAME\n",
    "cameras.rename(columns={' ':' '})\n",
    "\n",
    "# Avoir le poids moyen par marque ? On n'a pas la marque --> faire une colonne de marque\n",
    "\n",
    "# VOIR EXTRACT\n",
    "cameras['modele'].str.extract('^([A-Za-z])',)\n",
    "cameras['modele'].apply(lambda x : s.split(' ')[0])\n",
    "# ATTENTION : PANDAS, les assignements sont indexés par index => faire les alignements seulement si le DF de gauche a le meme index que le DF de droite.\n",
    "brand = ma serie meme shape que camera_clean\n",
    "brand.index = cameras_clean.index\n",
    "cameras_clean[brand]= brand\n",
    "# On peut aussi faire un join\n",
    "cameras_clean.join(brand)\n",
    "\n",
    "# quand on fait une assignation : DF.nouvelle col = nouvelle serie de autre DF, PANDAS assigne sur les index.\n",
    "\n",
    "# GROUPBY pour avoir le poids moyen par marque\n",
    "cameras_clean.groupby('brand')['weigth'].mean()\n",
    "cameras_clean.groupby('brand')['col1', 'col2', 'col3'].mean()\n",
    "\n",
    "# On peut faire différentes aggregations pour différentes colonnes : utiliser AGGREGATE AGG !\n",
    "# AGGREGATE : pour appliquer différentes fonctions sur différentes colonnes\n",
    "\n",
    "# VOIR LA DOC GROUPBY PANDAS\n",
    "\n",
    "# Avoir les top 5 résolutions par marque : \n",
    "# mon groupby : on passe soit une col, soit une lambda fonction\n",
    "camras_clean.groupby(lambda x: x.split(' ')[0]).apply(top_n) # On applique une custom fonction \n",
    "\n",
    "# Attention : un groupBy avec une lambda fonction s'applique forcément à l'index\n",
    "\n",
    "def top_n(df, n=5, columns=\"Max resolution\" ):\n",
    "    return df.\n",
    "    \n",
    "# Faire des catégories de prix : faire le guide d'achat de la Fnac. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUT ET QCUT faire des bins étant donné une série: bornes uniforméments réparties, ou des groupes uniforméments répartis (uniforme sur l'intervalle ou sur la répartition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.qcut(df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
