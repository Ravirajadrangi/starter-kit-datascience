{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par hab : 2 308 \n",
      "Par strate : 2 308 \n"
     ]
    }
   ],
   "source": [
    "########### INFO : SEUL LE DERNIER BLOC EST A CORRIGER, le reste n'est que de la construction ! ############\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "####   REMARQUE : en quoi c'est utile ? \n",
    "#\n",
    "# Pour le travail de crawling que je vous ai demandé vous aurez besoin de connaitre les selecteurs css.  \n",
    "#Voici une page qui présente ce que c'est , à lire absolument . \n",
    "#Notamment vous aurez besoin des selecteur nth-of-type.\n",
    "#\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Récupération des données sur 2013\n",
    "\n",
    "# on donne l'url\n",
    "url='http://alize2.finances.gouv.fr/communes/eneuro/detail.php?icom=056&dep=075&type=BPS&param=5&exercice=2013'\n",
    "result = requests.get(url)\n",
    "soup = BeautifulSoup(result.text, 'html.parser')\n",
    "\n",
    "list = soup.find_all(class_='montantpetit G')\n",
    "A_hab = list[1].text.replace('<td class=\"montantpetit G\">','')\n",
    "A_strate = list[2].text.replace('<td class=\"montantpetit G\">','')\n",
    "\n",
    "\n",
    "print 'A = Par hab :', A_hab\n",
    "print 'A = Par strate :', A_strate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = Par hab : 2 308 \n",
      "A = Par strate : 2 308 \n",
      "B = Par hab : 2 235 \n",
      "B = Par strate : 2 235 \n",
      "C = Par hab : 1 157 \n",
      "C = Par strate : 1 157 \n",
      "D = Par hab : 1 048 \n",
      "D = Par strate : 1 048 \n",
      "{'B_strate': 2235, 'A_strate': 2308, 'D_hab': 1048, 'C_strate': 1157, 'A_hab': 2308, 'C_hab': 1157, 'D_strate': 1048, 'B_hab': 2235}\n"
     ]
    }
   ],
   "source": [
    "##### Maintenant que j'ai le A, je peux faire la même chose avec le B, C et D\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Récupération des données sur 2013\n",
    "\n",
    "# on donne l'url\n",
    "url='http://alize2.finances.gouv.fr/communes/eneuro/detail.php?icom=056&dep=075&type=BPS&param=5&exercice=2013'\n",
    "\n",
    "def recup(url) :\n",
    "    tab={}\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "\n",
    "    list = soup.find_all(class_='montantpetit G')\n",
    "\n",
    "    A_h =list[1].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    A_hab=int(A_h.replace(\" \",''))\n",
    "    A_s = list[2].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    A_strate=int(A_s.replace(\" \",''))\n",
    "    \n",
    "    B_h = list[4].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    B_hab=int(B_h.replace(\" \",''))\n",
    "    B_s = list[5].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    B_strate=int(B_s.replace(\" \",''))\n",
    "\n",
    "    C_h = list[10].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    C_hab=int(C_h.replace(\" \",''))\n",
    "    C_s = list[11].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    C_strate=int(C_s.replace(\" \",''))\n",
    "\n",
    "    D_h = list[13].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    D_hab=int(D_h.replace(\" \",''))\n",
    "    D_s = list[14].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    D_strate=int(D_s.replace(\" \",''))\n",
    "    \n",
    "    tab['A_hab']=A_hab\n",
    "    tab['A_strate']=A_strate\n",
    "    tab['B_hab']=B_hab\n",
    "    tab['B_strate']=B_strate\n",
    "    tab['C_hab']=C_hab\n",
    "    tab['C_strate']=C_strate\n",
    "    tab['D_hab']=D_hab\n",
    "    tab['D_strate']=D_strate\n",
    "    \n",
    "    return tab\n",
    "\n",
    "#for el in list : \n",
    "#    print el, '\\n'\n",
    "\n",
    "#print 'A = Par hab :', A_hab\n",
    "#print 'A = Par strate :', A_strate\n",
    "#print 'B = Par hab :', B_hab\n",
    "#print 'B = Par strate :', B_strate\n",
    "#print 'C = Par hab :', C_hab\n",
    "#print 'C = Par strate :', C_strate\n",
    "#print 'D = Par hab :', D_hab\n",
    "#print 'D = Par strate :', D_strate\n",
    "print recup(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ville', 'annee', 'A_hab', 'A_strate', 'B_hab', 'B_strate', 'C_hab', 'C_strate', 'D_hab', 'D_strate'] \n",
      "\n",
      "['Paris', 2013, [2449, 2449, 2241, 2241, 1119, 1119, 1265, 1265]] \n",
      "\n",
      "['Paris', 2010, [2546, 2546, 2327, 2327, 1264, 1264, 1268, 1268]] \n",
      "\n",
      "['Paris', 2011, [2311, 2311, 2135, 2135, 1085, 1085, 1058, 1058]] \n",
      "\n",
      "['Paris', 2012, [2308, 2308, 2235, 2235, 1157, 1157, 1048, 1048]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### on en fait des fonctions et l'on boucle sur les années précédentes, avec un tableau de retour, et on retire les titres dans la liste (en tableau)\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def recup(url) :\n",
    "    tab=[]\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "\n",
    "    list = soup.find_all(class_='montantpetit G')\n",
    "\n",
    "    A_h =list[1].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    A_hab=int(A_h.replace(\" \",''))\n",
    "    A_s = list[2].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    A_strate=int(A_s.replace(\" \",''))\n",
    "    \n",
    "    B_h = list[4].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    B_hab=int(B_h.replace(\" \",''))\n",
    "    B_s = list[5].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    B_strate=int(B_s.replace(\" \",''))\n",
    "\n",
    "    C_h = list[10].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    C_hab=int(C_h.replace(\" \",''))\n",
    "    C_s = list[11].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    C_strate=int(C_s.replace(\" \",''))\n",
    "\n",
    "    D_h = list[13].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    D_hab=int(D_h.replace(\" \",''))\n",
    "    D_s = list[14].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    D_strate=int(D_s.replace(\" \",''))\n",
    "    \n",
    "    tab.append(A_hab)\n",
    "    tab.append(A_strate)\n",
    "    tab.append(B_hab)\n",
    "    tab.append(B_strate)\n",
    "    tab.append(C_hab)\n",
    "    tab.append(C_strate)\n",
    "    tab.append(D_hab)\n",
    "    tab.append(D_strate)\n",
    "    \n",
    "    return tab\n",
    "\n",
    "### Méthode principale ####\n",
    "\n",
    "#for i in range (2010, 2014): \n",
    "#    annee = i\n",
    "#    url='http://alize2.finances.gouv.fr/communes/eneuro/detail.php?icom=056&dep=075&type=BPS&param=5&exercice='+str(annee)\n",
    "#    print annee\n",
    "#    print recup(url)\n",
    "    \n",
    "### On va créer un tableau de tableau \n",
    "\n",
    "tab_final = [['ville', 'annee', 'A_hab', 'A_strate', 'B_hab', 'B_strate', 'C_hab', 'C_strate', 'D_hab', 'D_strate']]\n",
    "for i in range (2010, 2014):\n",
    "    tab = []\n",
    "    tab.append('Paris')\n",
    "    tab.append(annee)\n",
    "    annee = i\n",
    "    url='http://alize2.finances.gouv.fr/communes/eneuro/detail.php?icom=056&dep=075&type=BPS&param=5&exercice='+str(annee)\n",
    "    tab.append(recup(url))\n",
    "    tab_final.append(tab)\n",
    "# print tab_final\n",
    "\n",
    "### affichage final : \n",
    "\n",
    "for el in tab_final:\n",
    "    print el, '\\n'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected a string or other character buffer object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-06e6dbf7f381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmon_fichier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Paris.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmon_fichier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmon_fichier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected a string or other character buffer object"
     ]
    }
   ],
   "source": [
    "###### Maintenant on va essayer de l'enregistrer sous format txt --- ECHEC\n",
    "\n",
    "#mon_fichier = open(\"Paris.txt\", \"w\") \n",
    "\n",
    "#mon_fichier.write()\n",
    "\n",
    "#mon_fichier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ville', 'annee', 'A_hab', 'A_strate', 'B_hab', 'B_strate', 'C_hab', 'C_strate', 'D_hab', 'D_strate'] \n",
      "\n",
      "['Paris', 2013, [2449, 2449, 2241, 2241, 1119, 1119, 1265, 1265]] \n",
      "\n",
      "['Paris', 2010, [2546, 2546, 2327, 2327, 1264, 1264, 1268, 1268]] \n",
      "\n",
      "['Paris', 2011, [2311, 2311, 2135, 2135, 1085, 1085, 1058, 1058]] \n",
      "\n",
      "['Paris', 2012, [2308, 2308, 2235, 2235, 1157, 1157, 1048, 1048]] \n",
      "\n",
      "['Caen', 2013, [1356, 1355, 1180, 1235, 436, 531, 401, 521]] \n",
      "\n",
      "['Caen', 2010, [1330, 1383, 1226, 1258, 451, 507, 434, 526]] \n",
      "\n",
      "['Caen', 2011, [1353, 1419, 1204, 1296, 554, 583, 527, 583]] \n",
      "\n",
      "['Caen', 2012, [1489, 1434, 1292, 1330, 562, 595, 571, 600]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### On essaie de rajouter Caen, maintenant\n",
    "\n",
    "### on en fait des fonctions et l'on boucle sur les années précédentes, avec un tableau de retour, et on retire les titres dans la liste (en tableau)\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def recup(url) :\n",
    "    tab=[]\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "\n",
    "    list = soup.find_all(class_='montantpetit G')\n",
    "\n",
    "    A_h =list[1].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    A_hab=int(A_h.replace(\" \",''))\n",
    "    A_s = list[2].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    A_strate=int(A_s.replace(\" \",''))\n",
    "    \n",
    "    B_h = list[4].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    B_hab=int(B_h.replace(\" \",''))\n",
    "    B_s = list[5].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    B_strate=int(B_s.replace(\" \",''))\n",
    "\n",
    "    C_h = list[10].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    C_hab=int(C_h.replace(\" \",''))\n",
    "    C_s = list[11].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    C_strate=int(C_s.replace(\" \",''))\n",
    "\n",
    "    D_h = list[13].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    D_hab=int(D_h.replace(\" \",''))\n",
    "    D_s = list[14].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    D_strate=int(D_s.replace(\" \",''))\n",
    "    \n",
    "    tab.append(A_hab)\n",
    "    tab.append(A_strate)\n",
    "    tab.append(B_hab)\n",
    "    tab.append(B_strate)\n",
    "    tab.append(C_hab)\n",
    "    tab.append(C_strate)\n",
    "    tab.append(D_hab)\n",
    "    tab.append(D_strate)\n",
    "    \n",
    "    return tab\n",
    "\n",
    "### Caen : numero de commune : 118 numéro de departmt : 14 (merci Wikipedia)\n",
    "### Paris : numero de commune : 056 numero de departmt : 75\n",
    "\n",
    "tab_final = [['ville', 'annee', 'A_hab', 'A_strate', 'B_hab', 'B_strate', 'C_hab', 'C_strate', 'D_hab', 'D_strate']]\n",
    "for i in range (2010, 2014):\n",
    "    tab = []\n",
    "    tab.append('056')\n",
    "    tab.append('Paris')\n",
    "    tab.append(annee)\n",
    "    annee = i\n",
    "    url='http://alize2.finances.gouv.fr/communes/eneuro/detail.php?icom=056&dep=075&type=BPS&param=5&exercice='+str(annee)\n",
    "    tab.append(recup(url))\n",
    "    tab_final.append(tab)\n",
    "    \n",
    "for i in range (2010, 2014):\n",
    "    tab = []\n",
    "    tab.append('Caen')\n",
    "    tab.append(annee)\n",
    "    annee = i\n",
    "    url='http://alize2.finances.gouv.fr/communes/eneuro/detail.php?icom=118&dep=014&type=BPS&param=5&exercice='+str(annee)\n",
    "    tab.append(recup(url))\n",
    "    tab_final.append(tab)\n",
    "# print tab_final\n",
    "\n",
    "### affichage final : \n",
    "\n",
    "for el in tab_final:\n",
    "    print el, '\\n'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ville', 'annee', 'A_hab', 'A_strate', 'B_hab', 'B_strate', 'C_hab', 'C_strate', 'D_hab', 'D_strate'] \n",
      "\n",
      "['Paris', 2010, 2449, 2449, 2241, 2241, 1119, 1119, 1265, 1265] \n",
      "\n",
      "['Paris', 2010, 2546, 2546, 2327, 2327, 1264, 1264, 1268, 1268] \n",
      "\n",
      "['Paris', 2011, 2311, 2311, 2135, 2135, 1085, 1085, 1058, 1058] \n",
      "\n",
      "['Paris', 2012, 2308, 2308, 2235, 2235, 1157, 1157, 1048, 1048] \n",
      "\n",
      "['Caen', 2010, 1356, 1355, 1180, 1235, 436, 531, 401, 521] \n",
      "\n",
      "['Caen', 2011, 1330, 1383, 1226, 1258, 451, 507, 434, 526] \n",
      "\n",
      "['Caen', 2012, 1353, 1419, 1204, 1296, 554, 583, 527, 583] \n",
      "\n",
      "['Caen', 2013, 1489, 1434, 1292, 1330, 562, 595, 571, 600] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PARIS & CAEN de 2010 à 2013 \n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def recup(url) :\n",
    "    tab=[]\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "\n",
    "    list = soup.find_all(class_='montantpetit G')\n",
    "\n",
    "    A_h =list[1].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    A_hab=int(A_h.replace(\" \",''))\n",
    "    A_s = list[2].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    A_strate=int(A_s.replace(\" \",''))\n",
    "    \n",
    "    B_h = list[4].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    B_hab=int(B_h.replace(\" \",''))\n",
    "    B_s = list[5].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    B_strate=int(B_s.replace(\" \",''))\n",
    "\n",
    "    C_h = list[10].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    C_hab=int(C_h.replace(\" \",''))\n",
    "    C_s = list[11].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    C_strate=int(C_s.replace(\" \",''))\n",
    "\n",
    "    D_h = list[13].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    D_hab=int(D_h.replace(\" \",''))\n",
    "    D_s = list[14].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    D_strate=int(D_s.replace(\" \",''))\n",
    "    \n",
    "    tab.append(A_hab)\n",
    "    tab.append(A_strate)\n",
    "    tab.append(B_hab)\n",
    "    tab.append(B_strate)\n",
    "    tab.append(C_hab)\n",
    "    tab.append(C_strate)\n",
    "    tab.append(D_hab)\n",
    "    tab.append(D_strate)\n",
    "    \n",
    "    return tab\n",
    "\n",
    "### Caen : numero de commune : 118 numéro de departmt : 14 (merci Wikipedia)\n",
    "### Paris : numero de commune : 056 numero de departmt : 75\n",
    "# autre méthode : boucler sur les deux villes avec leurs caractéristiques, rentrées dans des tableaux. Pour 2 villes, on peut le faire à la main\n",
    "# ou faire un code qui recherche sur wikipedia le numero de ville et de departement pour l'intégrer dans l'url ?\n",
    "\n",
    "\n",
    "tab_final = [['ville', 'annee', 'A_hab', 'A_strate', 'B_hab', 'B_strate', 'C_hab', 'C_strate', 'D_hab', 'D_strate']]\n",
    "for i in range (2010, 2014):\n",
    "    tab = []\n",
    "    tab.append('Paris')\n",
    "    tab.append(annee)\n",
    "    annee = i\n",
    "    url='http://alize2.finances.gouv.fr/communes/eneuro/detail.php?icom=056&dep=075&type=BPS&param=5&exercice='+str(annee)\n",
    "    for i in range (8) : \n",
    "        tab.append(recup(url)[i])\n",
    "    tab_final.append(tab)\n",
    "    \n",
    "for i in range (2010, 2014):\n",
    "    tab = []\n",
    "    tab.append('Caen')\n",
    "    annee = i\n",
    "    tab.append(annee)\n",
    "    url='http://alize2.finances.gouv.fr/communes/eneuro/detail.php?icom=118&dep=014&type=BPS&param=5&exercice='+str(annee)\n",
    "    for i in range (8) : \n",
    "        tab.append(recup(url)[i])\n",
    "    tab_final.append(tab)\n",
    "\n",
    "### affichage final : \n",
    "\n",
    "for el in tab_final:\n",
    "    print el, '\\n'\n",
    "\n",
    "### Rq : il faut certainement l'extraire dans un fichier csv pour pouvoir l'étudier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n",
      "620\n",
      "640\n",
      "660\n",
      "680\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-2d785811a471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0ml6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0ml7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0ml8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0ml9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0ml10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "########################### CODE FINAL, PARIS & CALVADOS de 2010 à 2013 #############################################\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "def recup(url) :\n",
    "    tab=[]\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "\n",
    "    list = soup.find_all(class_='montantpetit G')\n",
    "\n",
    "    A_h =list[1].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    A_hab=int(A_h.replace(\" \",''))\n",
    "    A_s = list[2].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    A_strate=int(A_s.replace(\" \",''))\n",
    "    \n",
    "    B_h = list[4].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    B_hab=int(B_h.replace(\" \",''))\n",
    "    B_s = list[5].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    B_strate=int(B_s.replace(\" \",''))\n",
    "\n",
    "    C_h = list[10].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    C_hab=int(C_h.replace(\" \",''))\n",
    "    C_s = list[11].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    C_strate=int(C_s.replace(\" \",''))\n",
    "\n",
    "    D_h = list[13].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    D_hab=int(D_h.replace(\" \",''))\n",
    "    D_s = list[14].text.replace('<td class=\"montantpetit G\">','').replace(u'\\xa0','')\n",
    "    D_strate=int(D_s.replace(\" \",''))\n",
    "    \n",
    "    tab.append(A_hab)\n",
    "    tab.append(A_strate)\n",
    "    tab.append(B_hab)\n",
    "    tab.append(B_strate)\n",
    "    tab.append(C_hab)\n",
    "    tab.append(C_strate)\n",
    "    tab.append(D_hab)\n",
    "    tab.append(D_strate)\n",
    "    \n",
    "    return tab\n",
    "\n",
    "### Caen : numero de commune : 118 numéro de departmt : 14 (merci Wikipedia)\n",
    "### Paris : numero de commune : 056 numero de departmt : 75\n",
    "# autre méthode : boucler sur les deux villes avec leurs caractéristiques, rentrées dans des tableaux. Pour 2 villes, on peut le faire à la main\n",
    "# ou faire un code qui recherche sur wikipedia le numero de ville et de departement pour l'intégrer dans l'url ?\n",
    "\n",
    "#def url_ok(url):\n",
    "#    r = requests.head(url)\n",
    "#    return r.status_code == 200\n",
    "# on pourrait l'utiliser mais l'url marche meme quand la ville n'existe pas ! C'est une autre erreur sur la page\n",
    "\n",
    "tab_final = [['ville', 'annee', 'A_hab', 'A_strate', 'B_hab', 'B_strate', 'C_hab', 'C_strate', 'D_hab', 'D_strate']]\n",
    "for i in range (2010, 2014):\n",
    "    tab = []\n",
    "    tab.append('056')\n",
    "    tab.append('Paris')\n",
    "    annee = i\n",
    "    tab.append(annee)\n",
    "    url='http://alize2.finances.gouv.fr/communes/eneuro/detail.php?icom=056&dep=075&type=BPS&param=5&exercice='+str(annee)\n",
    "    for i in range (8) : \n",
    "        tab.append(recup(url)[i])\n",
    "    tab_final.append(tab)\n",
    "\n",
    "for num_ville in range (1,770) : # 765\n",
    "    num_ville_initial=num_ville\n",
    "    if num_ville%20==0 :\n",
    "        print num_ville\n",
    "    if num_ville<10 :\n",
    "        num_ville= str(\"00\"+str(num_ville))\n",
    "    if num_ville<100 : \n",
    "        num_ville = str(\"0\"+ str(num_ville))\n",
    "    #print \"num de ville :\", num_ville\n",
    "    for i in range (2010, 2014):\n",
    "        annee = i\n",
    "        #print \"annee\", annee\n",
    "        url='http://alize2.finances.gouv.fr/communes/eneuro/detail.php?icom='+str(num_ville)+'&dep=014&type=BPS&param=5&exercice='+str(annee)\n",
    "        result = requests.get(url)\n",
    "        soup = BeautifulSoup(result.text, 'html.parser')\n",
    "        #print (\"longueur\", len(soup.find_all(class_='G')))\n",
    "        \n",
    "        if len(soup.find_all(class_='G')) != 0 : \n",
    "            \n",
    "            liste = soup.find_all(class_='G')\n",
    "            #print liste[0]\n",
    "            \n",
    "            nom_ville=str(liste[1].text.replace('<td align=\"center\" class=\"G\" colspan=\"2\">','').replace('</td>', ''))\n",
    "            tab = []\n",
    "            tab.append(num_ville)\n",
    "            tab.append(nom_ville)\n",
    "            tab.append(annee)\n",
    "            for i in range (8) : \n",
    "                tab.append(recup(url)[i])\n",
    "            tab_final.append(tab)\n",
    "\n",
    "### affichage final : \n",
    "\n",
    "#for el in tab_final:\n",
    "#    print el, '\\n'\n",
    "\n",
    "from pandas import DataFrame\n",
    "l0=[]\n",
    "l1=[]\n",
    "l2=[]\n",
    "l3=[]\n",
    "l4=[]\n",
    "l5=[]\n",
    "l6=[]\n",
    "l7=[]\n",
    "l8=[]\n",
    "l9=[]\n",
    "l10=[]\n",
    "for i in range(1,len(tab_final)) : \n",
    "        l0.append(tab_final[i][0])\n",
    "        l1.append(tab_final[i][1])\n",
    "        l2.append(tab_final[i][2])\n",
    "        l3.append(tab_final[i][3])\n",
    "        l4.append(tab_final[i][4])\n",
    "        l5.append(tab_final[i][5])\n",
    "        l6.append(tab_final[i][6])\n",
    "        l7.append(tab_final[i][7])\n",
    "        l8.append(tab_final[i][8])\n",
    "        l9.append(tab_final[i][9])\n",
    "        l10.append(tab_final[i][10])\n",
    "df=DataFrame({'NumeroVille' : l0, 'Ville' : l1, 'Annee' : l2, 'A_hab': l3, 'A_strate' : l4,'B_hab': l5, 'B_strate' : l6,'C_hab': l7, 'C_strate' : l8,'D_hab': l9, 'D_strate' : l10 })\n",
    "print df\n",
    "\n",
    "df.to_excel('Calvados-total.xlsx', sheet_name='Calvados', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
